{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the seeds so the results are reproducible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task\n",
    "\n",
    "The website team wants to make it a bit more fun for customers to order pizza. They want to add a pizza button to their website called Adventure Time, which will automatically generate a set of ingredients that a person can order, and the chefs will cook. They saw an article by an MIT team and asked you if you can do something similar.\n",
    "\n",
    "### Understand the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have been lucky enough to find the exact same data that the team used and load it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_pizza = np.load(\"datasets/recipes/data_pizza.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pizza.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have 200 pizza recipes in there. Let's check them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': ['pizza'],\n",
      " 'directions': ['Preheat oven to 400 degrees F (200 degrees C). Grease a 9x13 '\n",
      "                'inch baking dish. Place ground beef in a large, deep skillet. '\n",
      "                'Cook over medium high heat until evenly brown. Stir in '\n",
      "                'pepperoni, and cook until browned. Drain excess fat. Stir in '\n",
      "                'pizza sauce. Remove from heat, and set aside.',\n",
      "                'Cut biscuits into quarters, and place in the bottom of baking '\n",
      "                'dish. Spread meat mixture evenly over the biscuits. Sprinkle '\n",
      "                'top with onion, olives and mushrooms.',\n",
      "                'Bake uncovered in preheated oven for 20 to 25 minutes. '\n",
      "                'Sprinkle top with mozzarella and Cheddar cheese. Bake an '\n",
      "                'additional 5 to 10 minutes, until cheese is melted. Let stand '\n",
      "                '10 minutes before serving.'],\n",
      " 'ingredients': [[1, '', 'beef', ''],\n",
      "                 [0.25, '', 'sausage', 'sliced'],\n",
      "                 [1, '', 'sauce', ''],\n",
      "                 [2, '', 'buttermilk', 'refrigerated'],\n",
      "                 [0.5, '', 'onion', 'sliced_separated'],\n",
      "                 [1, '', 'black', 'sliced'],\n",
      "                 [1, '', 'mushroom', 'sliced'],\n",
      "                 [1.5, '', 'mozzarella_cheese', 'shredded'],\n",
      "                 [1, '', 'cheese', 'shredded']],\n",
      " 'servings': ''}\n",
      "{'categories': ['pizza'],\n",
      " 'directions': ['Preheat the oven to 375 degrees F (190 degrees C).',\n",
      "                'Cook bacon in a large skillet and over medium-high heat, '\n",
      "                'turning occasionally, until evenly browned, about 10 minutes. '\n",
      "                'Drain bacon on paper towels and cool.',\n",
      "                'Pour oil into a 12-inch cast iron skillet. Brush oil all over '\n",
      "                'the interior of the skillet. Place dough into the pan and '\n",
      "                'shape into a pizza, forming a crust at the edge. Prick dough '\n",
      "                'all over with a fork.',\n",
      "                'Bake in the preheated oven for 5 minutes. Remove from oven '\n",
      "                'and reshape dough if necessary. Sprinkle the top of the dough '\n",
      "                'with 2 teaspoons ranch seasoning. Top with shredded '\n",
      "                'mozzarella, chicken, and red onion. Crumble cooled bacon on '\n",
      "                'top.',\n",
      "                'Bake in the preheated oven until cheese is melted and top is '\n",
      "                'browned, about 20 minutes.',\n",
      "                'Remove pizza from oven and top with tomato slices. Melt '\n",
      "                'butter and mix in the remaining dry ranch seasoning. Brush '\n",
      "                'crust with butter-ranch mixture.',\n",
      "                'Set an oven rack about 6 inches from the heat source and '\n",
      "                \"preheat the oven's broiler.\",\n",
      "                'Broil pizza until cheese is golden brown, 2 to 3 minutes, '\n",
      "                'being careful not to burn.'],\n",
      " 'ingredients': [[4, '', 'bacon', ''],\n",
      "                 [2, '', 'vegetable_oil', ''],\n",
      "                 [1, '', 'crust', 'refrigerated'],\n",
      "                 [6, '', 'mozzarella_cheese', 'shredded'],\n",
      "                 [0.3333333333333333, '', 'chicken', 'cubed'],\n",
      "                 [0.125, '', 'onion', 'sliced'],\n",
      "                 [1, '', 'tomato', 'sliced'],\n",
      "                 [1, '', 'butter', '']],\n",
      " 'servings': ''}\n",
      "{'categories': ['pizza'],\n",
      " 'directions': ['Preheat the oven to 400 degrees F (200 degrees C). Roll out '\n",
      "                'the bread dough into a rectangle, and spread out on a baking '\n",
      "                'sheet greased with olive oil. Set aside.',\n",
      "                'Place potato slices in a saucepan with enough water to cover. '\n",
      "                'Bring to a boil, and cook for about 5 minutes. Add bacon '\n",
      "                'slices to the water, and cook for an additional 5 minutes. '\n",
      "                'Drain. Remove bacon, then dice.',\n",
      "                'While the potatoes and bacon cook, melt the butter in a '\n",
      "                'skillet over medium heat. Add the onion, and cook, stirring '\n",
      "                'until tender. Remove from heat and stir in cream; season with '\n",
      "                'salt, pepper and nutmeg.',\n",
      "                'Spread the onion mixture over the bread dough. Arrange potato '\n",
      "                'slices evenly, and sprinkle with bacon.',\n",
      "                'Bake for 10 minutes in the preheated oven, until crust is '\n",
      "                'golden on the bottom. Let stand for a few minutes before '\n",
      "                'slicing.'],\n",
      " 'ingredients': [[18, '', 'bread', 'refrigerated'],\n",
      "                 [1, '', 'olive_oil', 'needed'],\n",
      "                 [1, '', 'potato', 'sliced'],\n",
      "                 [3, '', 'bacon', ''],\n",
      "                 [0.25, '', 'butter', ''],\n",
      "                 [0.5, '', 'onion', 'chopped'],\n",
      "                 [0.75, '', 'cream', ''],\n",
      "                 [1, '', 'nutmeg', ''],\n",
      "                 [None, '', 'pepper', '']],\n",
      " 'servings': ''}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "for entry in data_pizza[0:3]:\n",
    "    pprint(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot more information there than what you need. You only care about the ingredients so extract those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_only = [t['ingredients'] for t in data_pizza]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, '', 'beef', ''],\n",
       " [0.25, '', 'sausage', 'sliced'],\n",
       " [1, '', 'sauce', ''],\n",
       " [2, '', 'buttermilk', 'refrigerated'],\n",
       " [0.5, '', 'onion', 'sliced_separated'],\n",
       " [1, '', 'black', 'sliced'],\n",
       " [1, '', 'mushroom', 'sliced'],\n",
       " [1.5, '', 'mozzarella_cheese', 'shredded'],\n",
       " [1, '', 'cheese', 'shredded']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_only[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a single string per pizza recipe from these ingredients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_ingredients = []\n",
    "for set_of_ingredients in ingredients_only:\n",
    "    str_ingredients = ''\n",
    "    for ingredient in set_of_ingredients:\n",
    "        str_ingredients += ' '.join([str(t) for t in ingredient]) + ' '\n",
    "    joined_ingredients.append(str_ingredients.replace('  ', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 beef 0.25 sausage sliced 1 sauce 2 buttermilk refrigerated 0.5 onion sliced_separated 1 black sliced 1 mushroom sliced 1.5 mozzarella_cheese shredded 1 cheese shredded '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_ingredients[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks better. Now make it simpler and join up all the text in one large part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(joined_ingredients).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Convert the joined ingredients into a list of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39 different characters in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "vocabulary = sorted(set(text))\n",
    "\n",
    "character_to_number = {}\n",
    "\n",
    "for idx, character in enumerate(vocabulary):\n",
    "    character_to_number[character] = idx\n",
    "    \n",
    "number_to_character = np.array(vocabulary)\n",
    "\n",
    "print(f'There are {len(vocabulary)} different characters in the vocabulary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '.': 1,\n",
       " '0': 2,\n",
       " '1': 3,\n",
       " '2': 4,\n",
       " '3': 5,\n",
       " '4': 6,\n",
       " '5': 7,\n",
       " '6': 8,\n",
       " '7': 9,\n",
       " '8': 10,\n",
       " '9': 11,\n",
       " '_': 12,\n",
       " 'a': 13,\n",
       " 'b': 14,\n",
       " 'c': 15,\n",
       " 'd': 16,\n",
       " 'e': 17,\n",
       " 'f': 18,\n",
       " 'g': 19,\n",
       " 'h': 20,\n",
       " 'i': 21,\n",
       " 'j': 22,\n",
       " 'k': 23,\n",
       " 'l': 24,\n",
       " 'm': 25,\n",
       " 'n': 26,\n",
       " 'o': 27,\n",
       " 'p': 28,\n",
       " 'q': 29,\n",
       " 'r': 30,\n",
       " 's': 31,\n",
       " 't': 32,\n",
       " 'u': 33,\n",
       " 'v': 34,\n",
       " 'w': 35,\n",
       " 'x': 36,\n",
       " 'y': 37,\n",
       " 'z': 38}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_to_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ingredients text to an array of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_numbers = [character_to_number[character] for character in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the characters map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1 beef 0.25 s\" maps to: [3, 0, 14, 17, 17, 18, 0, 2, 1, 4, 7, 0, 31]\n"
     ]
    }
   ],
   "source": [
    "print(f'\"{text[:13]}\" maps to: {text_as_numbers[:13]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Split the text into chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You split the text into 1807 of 15 characters\n"
     ]
    }
   ],
   "source": [
    "chunk_length = 15\n",
    "\n",
    "chunk_length_with_extra_character = chunk_length + 1\n",
    "\n",
    "chunks = []\n",
    "for idx in range(0, len(text_as_numbers), chunk_length_with_extra_character):\n",
    "    chunks.append(text_as_numbers[idx:idx+chunk_length_with_extra_character])\n",
    "\n",
    "print(f'You split the text into {len(chunks)} of {chunk_length} characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number sequence: [3, 0, 14, 17, 17, 18, 0, 2, 1, 4, 7, 0, 31, 13, 33, 31]\n",
      "As text: 1 beef 0.25 saus\n",
      "\n",
      "Number sequence: [13, 19, 17, 0, 31, 24, 21, 15, 17, 16, 0, 3, 0, 31, 13, 33]\n",
      "As text: age sliced 1 sau\n",
      "\n",
      "Number sequence: [15, 17, 0, 4, 0, 14, 33, 32, 32, 17, 30, 25, 21, 24, 23, 0]\n",
      "As text: ce 2 buttermilk \n",
      "\n",
      "Number sequence: [30, 17, 18, 30, 21, 19, 17, 30, 13, 32, 17, 16, 0, 2, 1, 7]\n",
      "As text: refrigerated 0.5\n",
      "\n",
      "Number sequence: [0, 27, 26, 21, 27, 26, 0, 31, 24, 21, 15, 17, 16, 12, 31, 17]\n",
      "As text:  onion sliced_se\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for number_chunk in chunks[:5]:\n",
    "    text_chunk = [number_to_character[item] for item in number_chunk]\n",
    "    print(f\"Number sequence: {number_chunk}\")\n",
    "    print(f\"As text: {''.join(text_chunk)}\")\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Now convert all the chunks into input (x) and target (y) chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    x.append(chunk[:-1])\n",
    "    y.append(chunk[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input chunk: 1 beef 0.25 sau\n",
      "Target chunk:  beef 0.25 saus\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input chunk: {''.join([number_to_character[item] for item in x[0]])}\")\n",
    "print(f\"Target chunk: {''.join([number_to_character[item] for item in y[0]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Now create batches of these chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_x = []\n",
    "batched_y = []\n",
    "\n",
    "for idx in range(0, min(len(x), len(y)), batch_size):\n",
    "    if (\n",
    "        len(x[idx:idx+batch_size]) == batch_size and \n",
    "        len(y[idx:idx+batch_size]) == batch_size\n",
    "    ):\n",
    "        batched_x.append(np.asarray(x[idx:idx+batch_size]))\n",
    "        batched_y.append(np.asarray(y[idx:idx+batch_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know have batches of data to train with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 28 batches of 64 chunks of 15 characters each.\n"
     ]
    }
   ],
   "source": [
    "print(f'You have {len(batched_x)} batches of {len(batched_x[0])} '\n",
    "      f'chunks of {len(batched_x[0][0])} characters each.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Your First Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first layer in the model will be an embedding layer. The embedding layer will convert the characters from having values from 0 to 39 to being represented by vectors, which allows the model to capture relationships between the characters. The embedding layer has the following configuration:\n",
    "\n",
    "Input shape is the size of the vocabulary.\n",
    "\n",
    "Batch_input_shape will be the size of the batches above - 64.\n",
    "\n",
    "Output shape will be the size of the vector that the characters will be transformed into - this is set to 256 dimensions, but feel free to change it.\n",
    "\n",
    "Next, add an LSTM layer with a memory size of 256. Set them up to return sequences such that the output is of the shape (number of samples, number of time steps, LSTM units) and be stateful - remember information between batches.\n",
    "\n",
    "The output layer has to be able to output the next character in the sequence. That means it needs to have as many neurons as there are characters in your vocabulary. For this final layer, use a dense setup with linear activation.\n",
    "\n",
    "You will need to change the embedding layer to accept smaller batches so bring everything together into one function that builds the model for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def create_model(batch_size):\n",
    "    input_layer = Embedding(\n",
    "        input_dim=len(vocabulary), \n",
    "        output_dim=256,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    )\n",
    "    hidden_layer = LSTM(\n",
    "        units=256, \n",
    "        return_sequences=True, \n",
    "        stateful=True\n",
    "    )\n",
    "    output_layer = Dense(units=len(vocabulary), activation='softmax')\n",
    "    rnn_model = Sequential([\n",
    "        input_layer,\n",
    "        hidden_layer,\n",
    "        output_layer,\n",
    "    ])\n",
    "    \n",
    "    return rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = create_model(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           9984      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 39)            10023     \n",
      "=================================================================\n",
      "Total params: 545,319\n",
      "Trainable params: 545,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your target data is encoded as numbers and not one-hot as usual, so you need to use sparse categorical cross-entropy instead of normal cross-entropy to make the algorithm aware of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time around, you will be saving the model as it trains after every epoch. That is because you want to change the embedding layer's settings to from using batches of 64 chunks data to only use one chunk when using the model.\n",
    "\n",
    "Set up Keras to store the model during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.6625\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6473\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 3.6282\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 3.6044\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 3.5690\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 3.5086\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.3890\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2190\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.4579\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.4431\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.2259\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.1189\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.1144\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.1402\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1603\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1639\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.1533\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.1327\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.1070\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.0830\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.0608\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.0408\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.0229\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0065\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.9933\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.9832\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9797\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.9724\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.9623\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.9503\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.9390\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.9292\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.9200\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.9122\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.8979\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.8828\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.8653\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.8444\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.8304\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.8134\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.7947\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.7758\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.7531\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.7340\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.7061\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.6861\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.6580\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6352\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.6031\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.5765\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.5483\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.5167\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.4935\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.4716\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.4337\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3959\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.3649\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.3364\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.3139\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.2773\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.2402\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.2136\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.1750\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.1542\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.1292\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.0955\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0804\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.0620\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.0141\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.9746\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.9642\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9294\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.9144\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.8932\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8717\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8589\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.8169\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.7910\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7991\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7764\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.7423\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7044\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.7200\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.6766\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6752\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6640\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.6277\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6043\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.5743\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.5815\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.5652\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5449\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5390\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5201\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.5059\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4761\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4771\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4550\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.4132\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4053\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4026\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3867\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3636\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3508\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.3430\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3485\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2882\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3049\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2989\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2953\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2670\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2585\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2377\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2466\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2354\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2120\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1837\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1806\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1557\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1643\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1442\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1157\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1218\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1204\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1096\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0985\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0564\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0768\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0578\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0357\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0296\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0305\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0169\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9948\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9858\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9924\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9833\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9520\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9574\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9444\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9184\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9181\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9036\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9062\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8918\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8959\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8858\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8509\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8650\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8489\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8363\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8302\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8203\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7890\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7737\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7877\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7680\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7836\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7342\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7491\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7322\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7515\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7340\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7159\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7043\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7308\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7013\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6751\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6817\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6840\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6780\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6702\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6655\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6726\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6422\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6489\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6275\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6311\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6560\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6373\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6251\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6065\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6083\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5988\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5944\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5935\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5924\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6234\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5712\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5674\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5455\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5727\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5623\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5500\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5626\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5649\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.5392\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5526\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.5175\n"
     ]
    }
   ],
   "source": [
    "history = rnn_model.fit(\n",
    "    batched_x, \n",
    "    batched_y, \n",
    "    epochs=200, \n",
    "    callbacks=[checkpoint_callback],\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained. It's now time to build a new version of it that takes in 1 batch of 1 character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.train import latest_checkpoint\n",
    "from tensorflow import TensorShape\n",
    "\n",
    "latest_checkpoint = latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "single_input_rnn_model = create_model(batch_size=1)\n",
    "single_input_rnn_model.load_weights(latest_checkpoint)\n",
    "single_input_rnn_model.build(TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate lists of ingredients, first determine the average size of a list of ingredients from your input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143.5\n"
     ]
    }
   ],
   "source": [
    "average_length_ingredients = np.mean([len(t) for t in joined_ingredients])\n",
    "print(average_length_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "output_sequence_length = int(np.round(average_length_ingredients))\n",
    "print(output_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the model, you can choose a starting character that will then be converted to a number and fed to the model. The model will output a probability from 0 to 100% of what the next character should be. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_character = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atonion sliced_seast 1 gliced 1 mushroom 1 beef 0.25 saustared 1 clove 1 oril 1 crust refrigerated 0.5 onion chopped 1 dreded 1 chopped 1 green_o\n"
     ]
    }
   ],
   "source": [
    "# convert starting character to a number and store it as a (batch, sample)\n",
    "model_input = [[character_to_number[s] for s in starting_character]]\n",
    "\n",
    "# store the generated text in here\n",
    "generated_text = []\n",
    "\n",
    "# reset the model\n",
    "single_input_rnn_model.reset_states()\n",
    "\n",
    "for i in range(output_sequence_length):\n",
    "    predictions = single_input_rnn_model.predict(model_input)\n",
    "\n",
    "    # np.argmax only returns the max of the predictions\n",
    "    predicted_id = np.argmax(predictions)\n",
    "\n",
    "    # use the predicted character as input now\n",
    "    model_input = np.array([np.array([predicted_id])])\n",
    "\n",
    "    generated_text.append(number_to_character[predicted_id])\n",
    "\n",
    "print(starting_character + ''.join(generated_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the ingredients are not perfect words! But humans can see some similarities to known words. The website team can't wait to set up the system. The chefs will be able to swap unclear ingredients with whatever they think works best. Will you also order one?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
